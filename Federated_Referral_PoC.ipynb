{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrzioyEWX5rC+4Cts86qqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GQ131/24-Frames-in-Data-Film-Data-Set-Analysis/blob/main/Federated_Referral_PoC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== Federated Referral PoC (Option A) ==================\n",
        "# Rural-only, ZIP→Lat/Long/County join, loop preview, Tableau-ready CSV\n",
        "# Time window: Jan 1–Dec 31, 2024 | Program: RSEP\n",
        "# ======================================================================\n",
        "from google.colab import files\n",
        "import pandas as pd, numpy as np, uuid, re\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "1An-zM9sopVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "bb6b3b5b-c523-494e-c492-fc07255b6196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4498a81-9386-47f8-9f80-5548c886ecbc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4498a81-9386-47f8-9f80-5548c886ecbc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ALRB_cases.xlsx to ALRB_cases (7).xlsx\n",
            "Saving California_Zip_Lat_Lng_City_State_County.csv to California_Zip_Lat_Lng_City_State_County (8).csv\n",
            "Saving DOSH_cases.xlsx to DOSH_cases (7).xlsx\n",
            "Saving LCO_cases.xlsx to LCO_cases (7).xlsx\n",
            "User uploaded file \"ALRB_cases (7).xlsx\" with length 32512 bytes\n",
            "User uploaded file \"California_Zip_Lat_Lng_City_State_County (8).csv\" with length 129174 bytes\n",
            "User uploaded file \"DOSH_cases (7).xlsx\" with length 26364811 bytes\n",
            "User uploaded file \"LCO_cases (7).xlsx\" with length 680909 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Update these paths to your uploaded files in Colab ----\n",
        "ZIP_LATLONG_PATH = \"/content/California_Zip_Lat_Lng_City_State_County.csv\"  # has: Country, State/Province, ZIP Code/Postcode, Latitude, Longitude, County, City\n",
        "DLSE_PATH        = \"/content/LCO_cases.xlsx\"\n",
        "ALRB_PATH        = \"/content/ALRB_cases.xlsx\"\n",
        "CALOSHA_PATH     = \"/content/DOSH_cases.xlsx\"\n"
      ],
      "metadata": {
        "id": "CIdhclxjoE9M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQTEoHj-qVKk",
        "outputId": "878f7579-ddff-4998-8145-90a498bcb301"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'DOSH_cases (3).xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County (2).csv',\n",
              " 'LCO_cases (2).xlsx',\n",
              " 'ALRB_cases (2).xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County (8).csv',\n",
              " 'California_Zip_Lat_Lng_City_State_County (6).csv',\n",
              " 'California_Zip_Lat_Lng_City_State_County (5).csv',\n",
              " 'California_Zip_Lat_Lng_City_State_County (1).csv',\n",
              " 'LCO_cases (7).xlsx',\n",
              " 'ALRB_cases.xlsx',\n",
              " 'DOSH_cases (6).xlsx',\n",
              " 'ALRB_cases (4).xlsx',\n",
              " 'ALRB_cases (6).xlsx',\n",
              " 'DOSH_cases (5).xlsx',\n",
              " 'DOSH_cases (2).xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County (4).csv',\n",
              " 'DOSH_cases (7).xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County (7).csv',\n",
              " 'ALRB_cases (7).xlsx',\n",
              " 'ALRB_cases (5).xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County (3).csv',\n",
              " 'DOSH_cases (1).xlsx',\n",
              " 'LCO_cases (6).xlsx',\n",
              " 'LCO_cases (5).xlsx',\n",
              " 'DOSH_cases (4).xlsx',\n",
              " 'tableau_referrals_poc_rural_only.csv',\n",
              " 'LCO_cases (3).xlsx',\n",
              " 'LCO_cases (1).xlsx',\n",
              " 'DOSH_cases.xlsx',\n",
              " 'LCO_cases (4).xlsx',\n",
              " 'ALRB_cases (1).xlsx',\n",
              " 'LCO_cases.xlsx',\n",
              " 'California_Zip_Lat_Lng_City_State_County.csv',\n",
              " 'ALRB_cases (3).xlsx',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- PoC knobs ----\n",
        "ALL_AGENCIES = [\"DIR\",\"Cal/OSHA\",\"DLSE\",\"ALRB\",\"EDD\"]\n",
        "PROGRAM_VALUE = \"RSEP\"\n",
        "LOOP_RATE = 0.08                       # ~8% second-hop preview\n",
        "MIN_SEND_LAG, MAX_SEND_LAG = 0, 7      # days intake -> referral\n",
        "MIN_STATUS_LAG, MAX_STATUS_LAG = 3, 21 # days referral -> first update\n",
        "TARGET_MAX_ROWS = 600\n",
        "YEARS = {2023, 2024}"
      ],
      "metadata": {
        "id": "b6Jgkw7ioGnh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Canonical output columns (used everywhere to keep shape stable)\n",
        "COLS_CANON = [\n",
        "    \"Referral_UID\",\"Complaint_Intake_Date\",\"Referral_Sent_Date\",\n",
        "    \"Origin_Agency\",\"Destination_Agency\",\"Program\",\n",
        "    \"County\",\"ZIP\",\"Latitude\",\"Longitude\",\"Is_Rural_Worker\",\n",
        "    \"Referral_Status\",\"Response_Completed\",\"Days_To_First_Status_Update\",\n",
        "    \"Loop_Destination_Agency\",\"Loop_Referral_Sent_Date\",\n",
        "]"
      ],
      "metadata": {
        "id": "gNXdBzSanK8R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Curated rural counties list (tune if needed)\n",
        "RURAL_COUNTIES = {\n",
        "    \"Amador\",\"Calaveras\",\"Colusa\",\"Del Norte\",\"El Dorado\",\"Glenn\",\"Humboldt\",\"Imperial\",\"Inyo\",\n",
        "    \"Kings\",\"Lake\",\"Lassen\",\"Madera\",\"Mariposa\",\"Mendocino\",\"Merced\",\"Modoc\",\"Mono\",\"Napa\",\n",
        "    \"Nevada\",\"Placer\",\"Plumas\",\"San Benito\",\"Shasta\",\"Sierra\",\"Siskiyou\",\"Sutter\",\"Tehama\",\n",
        "    \"Trinity\",\"Tulare\",\"Tuolumne\",\"Yuba\",\"Kern\", \"Fresno\", \"Stanislaus\"\n",
        "}\n",
        "\n",
        "# ---- Helpers ----\n",
        "def zip5(z):\n",
        "    if pd.isna(z):\n",
        "        return \"\"\n",
        "    s = str(z).strip()\n",
        "    m = re.search(r\"(\\d{5})\", s)\n",
        "    return m.group(1) if m else \"\"\n",
        "\n",
        "def coerce_date(s):\n",
        "    return pd.to_datetime(s, errors=\"coerce\")\n",
        "\n",
        "def normalize_status_from_closed(closed_date, status_hint=None):\n",
        "    if pd.notna(closed_date):\n",
        "        return \"Closed\"\n",
        "    if status_hint is not None and isinstance(status_hint, str):\n",
        "        sl = status_hint.lower()\n",
        "        if any(k in sl for k in [\"close\",\"settle\",\"resolved\",\"dismiss\"]):\n",
        "            return \"Closed\"\n",
        "        if any(k in sl for k in [\"progress\",\"investigat\",\"acknow\"]):\n",
        "            return \"In Progress\"\n",
        "    return \"In Progress\"\n",
        "\n",
        "def choose_destination(origin, weights):\n",
        "    w = dict(weights) if weights else {origin: 0.6}\n",
        "    for a in ALL_AGENCIES:\n",
        "        w.setdefault(a, 0.0)\n",
        "    agencies, probs = zip(*w.items())\n",
        "    probs = np.array(probs, dtype=float)\n",
        "    probs = probs / probs.sum() if probs.sum() else np.ones_like(probs)/len(probs)\n",
        "    return np.random.choice(agencies, p=probs)\n",
        "\n",
        "def pick_status_and_completion(closed_flag):\n",
        "    if closed_flag:\n",
        "        return \"Closed\",\"Y\"\n",
        "    return np.random.choice([\"In Progress\",\"Open\"], p=[0.75,0.25]), np.random.choice([\"Y\",\"N\"], p=[0.5,0.5])\n",
        "\n",
        "def load_xlsx(path, sheet=None, header=None):\n",
        "    if sheet is None:\n",
        "        # read all sheets with default header=0\n",
        "        x = pd.read_excel(path, sheet_name=None)\n",
        "        frames = []\n",
        "        for name, df in x.items():\n",
        "            df = df.copy()\n",
        "            df[\"__sheet__\"] = name\n",
        "            frames.append(df)\n",
        "        return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
        "    # default to header=0 unless a custom header row is provided\n",
        "    return pd.read_excel(path, sheet_name=sheet, header=0 if header is None else header)\n",
        "\n"
      ],
      "metadata": {
        "id": "DP8sk3uUoQGw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Load ZIP→Lat/Long/County lookup and normalize ZIP ----\n",
        "geo = pd.read_csv(ZIP_LATLONG_PATH, dtype=str, keep_default_na=False)\n",
        "zip_col = \"ZIP Code/Postcode\"; lat_col = \"Latitude\"; lon_col = \"Longitude\"; county_col = \"County\"\n",
        "geo = geo.rename(columns={zip_col:\"ZIP5\", lat_col:\"Latitude\", lon_col:\"Longitude\", county_col:\"GeoCounty\"})\n",
        "geo[\"ZIP5\"] = geo[\"ZIP5\"].apply(zip5)\n",
        "geo = geo[(geo[\"ZIP5\"]!=\"\") & (geo[\"GeoCounty\"]!=\"\")]\n",
        "geo = geo[[\"ZIP5\",\"Latitude\",\"Longitude\",\"GeoCounty\"]].drop_duplicates()"
      ],
      "metadata": {
        "id": "1JOyjPmpoZ_5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Agency configs (based on your columns) ----\n",
        "CONFIG = {\n",
        "    \"DLSE\": {\n",
        "        \"path\": DLSE_PATH, \"origin\": \"DLSE\", \"sheet\": 0,\n",
        "        \"cols\": {\n",
        "            \"intake_date\": \"Case Management: Created Date\",\n",
        "            \"closed_date\": \"Case Closed Date\",\n",
        "            \"county\": None,\n",
        "            \"zip\": \"Employer: Primary Zip/Postal Code\",\n",
        "            \"status_hint\": None,\n",
        "            \"case_id\": \"Case Management: DIR Case Name\",\n",
        "        },\n",
        "        \"routing_weights\": {\"DLSE\": 0.60, \"Cal/OSHA\": 0.20, \"DIR\": 0.10, \"ALRB\": 0.05, \"EDD\": 0.05},\n",
        "    },\n",
        "    \"ALRB\": {\n",
        "        \"path\": ALRB_PATH, \"origin\": \"ALRB\", \"sheet\": None,\n",
        "        \"cols\": {\n",
        "            \"intake_date\": \"Filed Date\",\n",
        "            \"closed_date\": None,\n",
        "            \"county\": \"County\",\n",
        "            \"zip\": None,\n",
        "            \"status_hint\": \"Outcome\",\n",
        "            \"case_id\": \"Case Number\",\n",
        "        },\n",
        "        \"routing_weights\": {\"ALRB\": 0.65, \"DLSE\": 0.10, \"Cal/OSHA\": 0.10, \"DIR\": 0.10, \"EDD\": 0.05},\n",
        "    },\n",
        "\n",
        "    # In your CONFIG block for Cal/OSHA:\n",
        "    \"Cal/OSHA\": {\n",
        "        \"path\": CALOSHA_PATH, \"origin\": \"Cal/OSHA\",\n",
        "        \"sheet\": \"Complaints\",\n",
        "        \"header_row\": 14,\n",
        "        \"cols\": {\n",
        "            \"intake_date\": \"Open Conf Date\",\n",
        "            \"closed_date\": \"Closed Date\",\n",
        "            \"county\": \"GeoCounty\",   # <- use GeoCounty\n",
        "            \"zip\": \"GeoZip\",         # <- use GeoZip\n",
        "            \"status_hint\": None,\n",
        "            \"case_id\": \"RID\",\n",
        "        },\n",
        "        \"routing_weights\": {\"Cal/OSHA\": 0.50, \"DLSE\": 0.30, \"DIR\": 0.10, \"ALRB\": 0.05, \"EDD\": 0.05},\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "-MCx_r_TodwD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mx9pla3Pn7_I"
      },
      "outputs": [],
      "source": [
        "# ---- Builder per agency (handles blanks, uneven sizes, 2024 filter) ----\n",
        "\n",
        "def empty_out():\n",
        "    \"\"\"Return an empty dataframe with canonical columns.\"\"\"\n",
        "    return pd.DataFrame({c: pd.Series(dtype=\"object\") for c in COLS_CANON})[COLS_CANON]\n",
        "\n",
        "def build_from_agency(cfg):\n",
        "    df_raw = load_xlsx(cfg[\"path\"], cfg.get(\"sheet\"), cfg.get(\"header_row\"))\n",
        "    if df_raw is None or df_raw.empty:\n",
        "        return empty_out()\n",
        "\n",
        "    c = cfg[\"cols\"]; ori = cfg[\"origin\"]\n",
        "\n",
        "    # graceful fallbacks\n",
        "    if c.get(\"county\") and c[\"county\"] not in df_raw.columns and \"County\" in df_raw.columns:\n",
        "        c[\"county\"] = \"County\"\n",
        "    if c.get(\"zip\") and c[\"zip\"] not in df_raw.columns:\n",
        "        if \"Site  Zip\" in df_raw.columns:\n",
        "            c[\"zip\"] = \"Site  Zip\"\n",
        "\n",
        "    # Required intake date column must exist\n",
        "    if not c.get(\"intake_date\") or c[\"intake_date\"] not in df_raw.columns:\n",
        "        return empty_out()\n",
        "\n",
        "    intake = coerce_date(df_raw[c[\"intake_date\"]])\n",
        "    closed = coerce_date(df_raw[c[\"closed_date\"]]) if c.get(\"closed_date\") and c[\"closed_date\"] in df_raw.columns else pd.Series(pd.NaT, index=df_raw.index)\n",
        "    status_hint = df_raw[c[\"status_hint\"]] if c.get(\"status_hint\") and c[\"status_hint\"] in df_raw.columns else None\n",
        "\n",
        "    # Years\n",
        "    mask_years = intake.notna() & (intake.dt.year.isin(YEARS))\n",
        "    if not mask_years.any():\n",
        "        return empty_out()\n",
        "\n",
        "    df = df_raw.loc[mask_years].copy()\n",
        "    intake = intake.loc[mask_years]\n",
        "    closed = closed.loc[mask_years] if isinstance(closed, pd.Series) else pd.Series(pd.NaT, index=df.index)\n",
        "    if isinstance(status_hint, pd.Series):\n",
        "        status_hint = status_hint.loc[mask_years]\n",
        "\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    out[\"Referral_UID\"] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
        "    out[\"Complaint_Intake_Date\"] = intake.dt.date\n",
        "\n",
        "    # Referral sent date\n",
        "    send_lag = np.random.randint(MIN_SEND_LAG, MAX_SEND_LAG+1, size=len(df))\n",
        "    ref_sent = (intake + pd.to_timedelta(send_lag, unit=\"D\"))\n",
        "    out[\"Referral_Sent_Date\"] = ref_sent.dt.date\n",
        "    out[\"Origin_Agency\"] = ori\n",
        "    out[\"Program\"] = PROGRAM_VALUE\n",
        "\n",
        "    # ZIP normalized → 5-digit\n",
        "    if c.get(\"zip\") and c[\"zip\"] in df.columns:\n",
        "        out[\"ZIP\"] = df[c[\"zip\"]].apply(zip5)\n",
        "    else:\n",
        "        out[\"ZIP\"] = \"\"\n",
        "\n",
        "    # County: direct if present, else infer from ZIP via geo\n",
        "    if c.get(\"county\") and c[\"county\"] in df.columns:\n",
        "        county_series = df[c[\"county\"]].fillna(\"\").astype(str).str.strip()\n",
        "    else:\n",
        "        county_series = pd.Series([\"\"]*len(df), index=df.index)\n",
        "\n",
        "    # Merge ZIP→(County, Lat, Lon)\n",
        "    z = out[[\"ZIP\"]].copy().rename(columns={\"ZIP\":\"ZIP5\"})\n",
        "    merged = z.merge(geo, how=\"left\", on=\"ZIP5\")\n",
        "\n",
        "    # *** Align merged to out's index to avoid shape mismatches ***\n",
        "    merged.index = out.index\n",
        "\n",
        "    # Lat/Lon from ZIP master (will be blank if ZIP missing/not found)\n",
        "    out[\"Latitude\"]  = merged[\"Latitude\"].fillna(\"\")\n",
        "    out[\"Longitude\"] = merged[\"Longitude\"].fillna(\"\")\n",
        "\n",
        "    # ----- County resolution (Policy: B and 1) -----\n",
        "    # Prefer County from ZIP master when ZIP is present; otherwise keep agency County.\n",
        "    county_from_agency = (\n",
        "        county_series.reindex(out.index)   # <-- align to out\n",
        "                    .fillna(\"\")\n",
        "                    .astype(str).str.strip()\n",
        "    )\n",
        "    county_from_zip = (\n",
        "        merged[\"GeoCounty\"].fillna(\"\")\n",
        "                          .astype(str).str.strip()\n",
        "    )\n",
        "\n",
        "    out[\"County\"] = np.where(\n",
        "        (out[\"ZIP\"] != \"\") & (county_from_zip != \"\"),\n",
        "        county_from_zip,\n",
        "        county_from_agency\n",
        "    )\n",
        "\n",
        "    # Rural rule\n",
        "    out[\"Is_Rural_Worker\"] = out[\"County\"].apply(lambda cn: \"Y\" if cn in RURAL_COUNTIES else \"N\")\n",
        "\n",
        "    # Jurisdiction filter: rural only\n",
        "    out = out[out[\"Is_Rural_Worker\"]==\"Y\"].copy()\n",
        "    if out.empty:\n",
        "        return empty_out()\n",
        "\n",
        "    # Destination selection\n",
        "    weights = cfg.get(\"routing_weights\", {})\n",
        "    out[\"Destination_Agency\"] = [choose_destination(ori, weights) for _ in range(len(out))]\n",
        "\n",
        "    # Status & completion\n",
        "    closed_map = pd.Series(closed.values, index=df.index).loc[out.index]\n",
        "    if isinstance(status_hint, pd.Series):\n",
        "        status_hint_map = pd.Series(status_hint.values, index=df.index).loc[out.index]\n",
        "    else:\n",
        "        status_hint_map = pd.Series([None]*len(out), index=out.index)\n",
        "\n",
        "    norm_status = [\n",
        "        normalize_status_from_closed(closed_map.loc[i], status_hint_map.loc[i])\n",
        "        for i in out.index\n",
        "    ]\n",
        "    is_closed = [s == \"Closed\" for s in norm_status]\n",
        "    final_status, completed = [], []\n",
        "    for cl in is_closed:\n",
        "        s, comp = pick_status_and_completion(cl)\n",
        "        if cl: s, comp = \"Closed\",\"Y\"\n",
        "        final_status.append(s); completed.append(comp)\n",
        "    out[\"Referral_Status\"] = final_status\n",
        "    out[\"Response_Completed\"] = completed\n",
        "\n",
        "    # Days to first update\n",
        "    out[\"Days_To_First_Status_Update\"] = np.random.randint(MIN_STATUS_LAG, MAX_STATUS_LAG+1, size=len(out))\n",
        "\n",
        "    # Loop preview (~8%)\n",
        "    n = len(out)\n",
        "    mask_loop = np.random.rand(n) < LOOP_RATE\n",
        "    loop_dest, loop_date = [], []\n",
        "    for idx, m in zip(out.index, mask_loop):\n",
        "        if not m:\n",
        "            loop_dest.append(\"\"); loop_date.append(\"\")\n",
        "            continue\n",
        "        first_dest = out.loc[idx, \"Destination_Agency\"]\n",
        "        choices = [a for a in ALL_AGENCIES if a != first_dest]\n",
        "        loop_dest.append(np.random.choice(choices))\n",
        "        d0 = pd.to_datetime(out.loc[idx, \"Referral_Sent_Date\"])\n",
        "        loop_date.append((d0 + timedelta(days=int(np.random.randint(2,11)))).date())\n",
        "    out[\"Loop_Destination_Agency\"] = loop_dest\n",
        "    out[\"Loop_Referral_Sent_Date\"] = loop_date\n",
        "\n",
        "    # Ensure canonical order\n",
        "    for ccc in COLS_CANON:\n",
        "        if ccc not in out.columns:\n",
        "            out[ccc] = \"\"\n",
        "    return out[COLS_CANON]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Build all and export ------------------\n",
        "frames = []\n",
        "for key, cfg in CONFIG.items():\n",
        "    print(f\"Processing: {key}\")\n",
        "    frames.append(build_from_agency(cfg))\n",
        "\n",
        "# If everything came back empty, still produce a CSV with headers\n",
        "if len(frames) == 0:\n",
        "    final = empty_out()\n",
        "else:\n",
        "    final = pd.concat(frames, ignore_index=True) if any(not f.empty for f in frames) else empty_out()\n",
        "\n",
        "# Cap size for PoC if very large; sort by date for nicer Tableau behavior\n",
        "if len(final) > TARGET_MAX_ROWS:\n",
        "    final = final.sample(TARGET_MAX_ROWS, random_state=42).sort_values(\"Referral_Sent_Date\")\n",
        "\n",
        "# --- FINAL TYPE HYGIENE BEFORE EXPORT ---\n",
        "\n",
        "# ZIP as text\n",
        "final[\"ZIP\"] = final[\"ZIP\"].astype(str)\n",
        "\n",
        "# Lat/Lon as float when possible, else blank string\n",
        "for col in [\"Latitude\",\"Longitude\"]:\n",
        "    final[col] = pd.to_numeric(final[col], errors=\"coerce\")\n",
        "    final[col] = final[col].apply(lambda x: \"\" if pd.isna(x) else x)\n",
        "\n",
        "# Dates to ISO strings\n",
        "for col in [\"Complaint_Intake_Date\",\"Referral_Sent_Date\",\"Loop_Referral_Sent_Date\"]:\n",
        "    final[col] = pd.to_datetime(final[col], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "OUT_PATH = \"/content/tableau_referrals_poc_rural_only.csv\"\n",
        "final.to_csv(OUT_PATH, index=False)\n",
        "print(f\"\\n✅ Wrote {OUT_PATH} with {len(final)} rural rows.\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "5OUDR0V-ojaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54461d5b-dc76-44fc-9a24-45c4a80670c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: DLSE\n",
            "Processing: ALRB\n",
            "Processing: Cal/OSHA\n",
            "\n",
            "✅ Wrote /content/tableau_referrals_poc_rural_only.csv with 600 rural rows.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================== (A) Preview Summary ==========================\n",
        "# Month & Origin counts, completion rate, avg days, loops count\n",
        "def month(d):\n",
        "    try:\n",
        "        return pd.to_datetime(d).strftime(\"%Y-%m\")\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "summary = final.copy()\n",
        "summary[\"Month\"] = summary[\"Referral_Sent_Date\"].apply(month)\n",
        "summary[\"Loop_Flag\"] = summary[\"Loop_Destination_Agency\"].apply(lambda x: 1 if isinstance(x, str) and x.strip() != \"\" else 0)\n",
        "\n",
        "grouped = summary.groupby([\"Month\",\"Origin_Agency\"], dropna=False).agg(\n",
        "    referrals=(\"Referral_UID\",\"count\"),\n",
        "    completed_pct=(\"Response_Completed\", lambda s: (s.eq(\"Y\").mean()*100).round(1) if len(s) else 0),\n",
        "    avg_days_to_update=(\"Days_To_First_Status_Update\",\"mean\"),\n",
        "    loops=(\"Loop_Flag\",\"sum\")\n",
        ").reset_index()\n",
        "\n",
        "print(\"=== Preview Summary (by Month & Origin_Agency) ===\")\n",
        "print(grouped.sort_values([\"Month\",\"Origin_Agency\"]).to_string(index=False))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S94iuuIhi3Vy",
        "outputId": "118a0faf-0205-4773-cd4b-4b70a94e94fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Preview Summary (by Month & Origin_Agency) ===\n",
            "  Month Origin_Agency  referrals  completed_pct avg_days_to_update  loops\n",
            "2023-01          DLSE         12          100.0              13.25      1\n",
            "2023-02          DLSE         13           92.3          11.769231      3\n",
            "2023-03          ALRB          2            0.0                8.0      0\n",
            "2023-03          DLSE         22           81.8          11.954545      0\n",
            "2023-04          DLSE         14           57.1          11.071429      0\n",
            "2023-05          ALRB          2           50.0               10.5      0\n",
            "2023-05          DLSE         14           85.7          14.285714      2\n",
            "2023-06          ALRB          3            0.0          16.666667      2\n",
            "2023-06          DLSE         14           85.7          12.357143      1\n",
            "2023-07          ALRB          3           33.3                9.0      1\n",
            "2023-07          DLSE         28           89.3          12.571429      0\n",
            "2023-08          ALRB          1            0.0                3.0      0\n",
            "2023-08          DLSE         14           71.4          10.857143      1\n",
            "2023-09          ALRB          1          100.0                4.0      0\n",
            "2023-09          DLSE         21           85.7               10.0      1\n",
            "2023-10          DLSE         26           76.9               11.5      4\n",
            "2023-11          DLSE         30           66.7          12.233333      4\n",
            "2023-12          DLSE         23           73.9          14.913043      3\n",
            "2024-01          ALRB          1            0.0               18.0      0\n",
            "2024-01          DLSE         14           50.0          12.571429      1\n",
            "2024-02          DLSE         21           81.0          12.095238      3\n",
            "2024-03          ALRB          4           25.0                9.5      0\n",
            "2024-03          DLSE         16           62.5             12.375      3\n",
            "2024-04          ALRB          4           50.0              12.25      0\n",
            "2024-04          DLSE         36           80.6          11.444444      5\n",
            "2024-05          ALRB          1          100.0               15.0      0\n",
            "2024-05          DLSE         15           73.3          13.866667      1\n",
            "2024-06          ALRB          2          100.0               10.0      0\n",
            "2024-06          DLSE         11           81.8          14.181818      0\n",
            "2024-07          ALRB          3           66.7          11.666667      1\n",
            "2024-07          DLSE         44           88.6          10.795455      3\n",
            "2024-08          ALRB          4           75.0              10.25      0\n",
            "2024-08          DLSE         46           73.9          13.521739      3\n",
            "2024-09          DLSE         39           84.6          11.589744      3\n",
            "2024-10          DLSE         38           57.9          12.736842      3\n",
            "2024-11          DLSE         32           56.2            12.4375      2\n",
            "2024-12          DLSE         24           62.5          10.833333      0\n",
            "2025-01          DLSE          2           50.0               16.5      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall quick KPIs\n",
        "overall = {\n",
        "    \"Total referrals\": len(final),\n",
        "    \"Completion rate (%)\": round(final[\"Response_Completed\"].eq(\"Y\").mean()*100, 1) if len(final) else 0,\n",
        "    \"Avg days to first update\": round(final[\"Days_To_First_Status_Update\"].mean(), 1) if len(final) else 0,\n",
        "    \"Loop share (%)\": round((summary[\"Loop_Flag\"].mean()*100), 1) if len(final) else 0,\n",
        "}\n",
        "print(\"\\n=== Overall KPIs ===\")\n",
        "for k,v in overall.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# ====================== (C) Sample Validation ========================\n",
        "print(\"\\n=== Sample 10 rows ===\")\n",
        "print(final.head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4jWTSKVi5bY",
        "outputId": "9ee5d69e-89ab-4356-fd6e-3da0b81ebe0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Overall KPIs ===\n",
            "Total referrals: 600\n",
            "Completion rate (%): 73.8\n",
            "Avg days to first update: 12.2\n",
            "Loop share (%): 8.5\n",
            "\n",
            "=== Sample 10 rows ===\n",
            "                        Referral_UID Complaint_Intake_Date Referral_Sent_Date Origin_Agency Destination_Agency Program   County   ZIP  Latitude  Longitude Is_Rural_Worker Referral_Status Response_Completed Days_To_First_Status_Update Loop_Destination_Agency Loop_Referral_Sent_Date\n",
            "a089764b-ee58-4e85-a266-cf25b9131722            2023-01-06         2023-01-12          DLSE               DLSE    RSEP     Lake 95467  38.80453 -122.54948               Y     In Progress                  Y                          15                                             NaN\n",
            "b7219e84-c0b5-4eab-a68d-930702577f81            2023-01-09         2023-01-13          DLSE               DLSE    RSEP    Kings 93245  36.28614 -119.83405               Y          Closed                  Y                          17                                             NaN\n",
            "643bc44e-2a5a-4bd4-a139-bf34949ff327            2023-01-09         2023-01-13          DLSE               DLSE    RSEP    Kings 93245  36.28614 -119.83405               Y          Closed                  Y                          14                                             NaN\n",
            "30153503-1d94-4c2f-880f-02a5d609ecb6            2023-01-13         2023-01-16          DLSE               DLSE    RSEP     Kern 93263  35.48722 -119.27835               Y          Closed                  Y                           6                                             NaN\n",
            "7ef27191-f677-4e75-914d-748b71d6968e            2023-01-17         2023-01-19          DLSE               DLSE    RSEP   Merced 95324  37.39452 -120.89605               Y     In Progress                  Y                          21                                             NaN\n",
            "5c76cf2e-b609-43b3-abde-74f224ea7e9e            2023-01-23         2023-01-23          DLSE                DIR    RSEP    Kings 93245  36.28614 -119.83405               Y          Closed                  Y                          11                                             NaN\n",
            "53934cc3-ebe5-474b-ba55-4032f3e6d7ae            2023-01-18         2023-01-23          DLSE               DLSE    RSEP   Madera 93638   37.0424 -120.03816               Y          Closed                  Y                           8                                             NaN\n",
            "789c1075-4620-4663-9733-da4ea63529c8            2023-01-23         2023-01-25          DLSE               DLSE    RSEP    Kings 93245  36.28614 -119.83405               Y          Closed                  Y                          11                                             NaN\n",
            "2e38fe06-60c0-4862-aa1f-294fb0521a97            2023-01-25         2023-01-26          DLSE           Cal/OSHA    RSEP   Tulare 93219  35.87908 -119.28818               Y          Closed                  Y                          19                                             NaN\n",
            "6661327d-2373-45b2-9871-1af9ad1454a0            2023-01-25         2023-01-28          DLSE               DLSE    RSEP Humboldt 95501  40.80435 -124.14034               Y          Closed                  Y                          14                                             NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_PATH = \"/content/tableau_referrals_poc_rural_only.csv\"\n",
        "final.to_csv(OUT_PATH, index=False)\n",
        "print(f\"\\n✅ Wrote {OUT_PATH} with {len(final)} rural rows.\\n\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "T4Ee2PHmtTkB",
        "outputId": "a9db5e28-5ee8-40d3-be60-98c212d97a6a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Wrote /content/tableau_referrals_poc_rural_only.csv with 600 rural rows.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6ffd5356-7551-4985-9a1c-f7c60d553393\", \"tableau_referrals_poc_rural_only.csv\", 75014)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List sheets\n",
        "xls = pd.ExcelFile(CALOSHA_PATH)\n",
        "print(\"Sheets:\", xls.sheet_names)\n",
        "\n",
        "# Peek columns from the sheet you're using (adjust index if needed)\n",
        "df_test = pd.read_excel(CALOSHA_PATH, sheet_name=0)\n",
        "print(\"Sheet[0] columns:\", list(df_test.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvYx8p4I5E7c",
        "outputId": "2073bff8-f771-407b-d191-7993517c9fb5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheets: ['Notes', 'References - Lists', 'Sheet1', 'Sheet3', 'Complaints', 'Industries- Tables', 'Industries - Charts', 'All Regions - Charts', 'Complaint vs Insp Coded', 'Heat Referrals', 'Comparison by NAICS', 'Comparison by YR', 'Other Inspections Coded', 'Totals by Ag Subsector', 'Sheet2', 'Region 1 - Charts', 'Region 2 - Charts', 'Region 3 - Charts', 'Region 4 - Charts', 'All Regions - Charts (2)']\n",
            "Sheet[0] columns: ['UPA One Liner Detail']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xls = pd.ExcelFile(CALOSHA_PATH)\n",
        "\n",
        "def find_col(df, targets):\n",
        "    norm = {c: c.strip().lower().replace(\".\", \"\").replace(\"_\", \"\").replace(\"  \", \" \")\n",
        "            for c in df.columns}\n",
        "    for t in targets:\n",
        "        tnorm = t.strip().lower().replace(\".\", \"\").replace(\"_\", \"\").replace(\"  \", \" \")\n",
        "        for c, cnorm in norm.items():\n",
        "            if cnorm == tnorm:\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "intake_targets = [\n",
        "    \"Open Conf Date\",\"Open Conf. Date\",\"Open Conference Date\",\n",
        "    \"Open ConfDate\",\"Open Conference Dt\",\"OpenConfDate\"\n",
        "]\n",
        "zip_targets = [\"GeoZip\",\"Geo Zip\",\"Site Zip\",\"Site  Zip\"]\n",
        "county_targets = [\"GeoCounty\",\"Geo County\",\"County\"]\n",
        "\n",
        "candidates = []\n",
        "for s in xls.sheet_names:\n",
        "    try:\n",
        "        df = pd.read_excel(CALOSHA_PATH, sheet_name=s)\n",
        "        ic = find_col(df, intake_targets)\n",
        "        zc = find_col(df, zip_targets)\n",
        "        cc = find_col(df, county_targets)\n",
        "        score = (ic is not None) + (zc is not None) + (cc is not None)\n",
        "        if score >= 2:  # needs intake + (zip or county)\n",
        "            candidates.append((s, ic, zc, cc, score, len(df.columns)))\n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "# sort: best score first, then more columns (more likely the raw table)\n",
        "candidates.sort(key=lambda x: (-x[4], -x[5]))\n",
        "print(\"Candidates (best first):\")\n",
        "for s, ic, zc, cc, score, ncols in candidates[:8]:\n",
        "    print(f\"  • Sheet='{s}' | intake='{ic}' | zip='{zc}' | county='{cc}' | score={score} | ncols={ncols}\")\n",
        "\n",
        "if not candidates:\n",
        "    print(\"No suitable sheet found. Try 'Complaints', 'Sheet1', or 'Sheet3' manually.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aEZlnZC5cR7",
        "outputId": "6cbcdb32-ccc7-4eed-cc45-9f20cdb5537f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidates (best first):\n",
            "No suitable sheet found. Try 'Complaints', 'Sheet1', or 'Sheet3' manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "LIKELY_SHEETS = [\"Complaints\", \"Sheet1\", \"Sheet3\"]\n",
        "\n",
        "def find_col(df, targets):\n",
        "    norm = {c: c.strip().lower().replace(\".\", \"\").replace(\"_\", \"\").replace(\"  \",\" \")\n",
        "            for c in df.columns}\n",
        "    for t in targets:\n",
        "        tnorm = t.strip().lower().replace(\".\", \"\").replace(\"_\", \"\").replace(\"  \",\" \")\n",
        "        for c, cnorm in norm.items():\n",
        "            if cnorm == tnorm:\n",
        "                return c\n",
        "    return None\n",
        "\n",
        "intake_candidates = [\"Open Conf Date\",\"Open Conf. Date\",\"Open Conference Date\",\"Open ConfDate\",\"Open Conference Dt\",\"OpenConfDate\"]\n",
        "zip_candidates    = [\"GeoZip\",\"Geo Zip\",\"Site Zip\",\"Site  Zip\"]\n",
        "county_candidates = [\"GeoCounty\",\"Geo County\",\"County\"]\n",
        "\n",
        "results = []\n",
        "for s in LIKELY_SHEETS:\n",
        "    try:\n",
        "        df = pd.read_excel(CALOSHA_PATH, sheet_name=s)\n",
        "        ic = find_col(df, intake_candidates)\n",
        "        zc = find_col(df, zip_candidates)\n",
        "        cc = find_col(df, county_candidates)\n",
        "        score = (ic is not None) + (zc is not None) + (cc is not None)\n",
        "        results.append((s, ic, zc, cc, score, len(df), len(df.columns)))\n",
        "    except Exception as e:\n",
        "        results.append((s, None, None, None, -1, 0, 0))\n",
        "\n",
        "print(\"Sheet scan (best first):\")\n",
        "for s, ic, zc, cc, score, nrows, ncols in sorted(results, key=lambda x: (-x[4], -x[5], -x[6])):\n",
        "    print(f\"  • {s:12s} | intake={ic} | zip={zc} | county={cc} | score={score} | rows={nrows} | cols={ncols}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ2wFVkB54CN",
        "outputId": "88e4965f-5f4d-44ea-a02f-285fedd5ea98"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet scan (best first):\n",
            "  • Complaints   | intake=None | zip=None | county=None | score=0 | rows=3059 | cols=116\n",
            "  • Sheet3       | intake=None | zip=None | county=None | score=0 | rows=57 | cols=7\n",
            "  • Sheet1       | intake=None | zip=None | county=None | score=0 | rows=55 | cols=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re\n",
        "\n",
        "SHEET = \"Complaints\"  # likely the raw table\n",
        "\n",
        "# patterns we expect to see somewhere in the header row\n",
        "PATTERNS = {\n",
        "    \"intake\":  re.compile(r\"open\\s*conf.*date\", re.I),\n",
        "    \"zip\":     re.compile(r\"\\bgeo\\s*zip\\b|\\bsite\\s*zip\\b\", re.I),\n",
        "    \"county\":  re.compile(r\"\\bgeo\\s*county\\b|\\bcounty\\b\", re.I),\n",
        "}\n",
        "\n",
        "# 1) read a small slice first without headers to find which row contains the header\n",
        "peek = pd.read_excel(CALOSHA_PATH, sheet_name=SHEET, header=None, nrows=30)\n",
        "header_row = None\n",
        "for i in range(len(peek)):\n",
        "    row_vals = [str(x) for x in peek.iloc[i].tolist()]\n",
        "    joined = \" | \".join(row_vals)\n",
        "    if any(p.search(joined) for p in PATTERNS.values()):\n",
        "        header_row = i\n",
        "        break\n",
        "\n",
        "print(\"Detected header row:\", header_row)\n",
        "\n",
        "# 2) re-read using that header row\n",
        "if header_row is None:\n",
        "    raise ValueError(\"Could not auto-detect a header row. Try increasing nrows or inspecting manually.\")\n",
        "\n",
        "df_calo = pd.read_excel(CALOSHA_PATH, sheet_name=SHEET, header=header_row)\n",
        "\n",
        "# 3) normalize headers (for matching & sanity)\n",
        "def norm(s):\n",
        "    s = str(s)\n",
        "    s = s.replace(\"\\xa0\",\" \")  # non-breaking spaces\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "df_calo.columns = [norm(c) for c in df_calo.columns]\n",
        "\n",
        "# 4) find the actual column names by regex matching on the cleaned headers\n",
        "def find_col_by_regex(cols, patt):\n",
        "    for c in cols:\n",
        "        if patt.search(c):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "intake_col = find_col_by_regex(df_calo.columns, PATTERNS[\"intake\"])\n",
        "zip_col    = find_col_by_regex(df_calo.columns, PATTERNS[\"zip\"])\n",
        "county_col = find_col_by_regex(df_calo.columns, PATTERNS[\"county\"])\n",
        "\n",
        "print(\"Resolved columns →\")\n",
        "print(\"  intake:\", intake_col)\n",
        "print(\"  zip   :\", zip_col)\n",
        "print(\"  county:\", county_col)\n",
        "\n",
        "# (optional) quick year counts to confirm we’ll retain rows\n",
        "years = pd.to_datetime(df_calo[intake_col], errors=\"coerce\").dt.year\n",
        "print(\"Counts by year:\\n\", years.value_counts().sort_index())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCCDbGdc6Zc9",
        "outputId": "56c60e9d-93a6-4815-af64-13d022cb0bbe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected header row: 14\n",
            "Resolved columns →\n",
            "  intake: Open Conf Date\n",
            "  zip   : Site Zip\n",
            "  county: Site County\n",
            "Counts by year:\n",
            " Open Conf Date\n",
            "2015.0    273\n",
            "2016.0    266\n",
            "2017.0    315\n",
            "2018.0    293\n",
            "2019.0    315\n",
            "2020.0    133\n",
            "2021.0    246\n",
            "2022.0    330\n",
            "2023.0    144\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Read with header row 15 (0-indexed 14)\n",
        "raw = pd.read_excel(CALOSHA_PATH, sheet_name=\"Complaints\", header=14)\n",
        "\n",
        "# Normalize headers (collapse weird spaces/punctuation)\n",
        "raw.columns = (\n",
        "    raw.columns.astype(str)\n",
        "       .str.replace(\"\\xa0\",\" \", regex=False)\n",
        "       .str.replace(r\"\\s+\",\" \", regex=True)\n",
        "       .str.strip()\n",
        ")\n",
        "\n",
        "def pick_col(df, preferred, candidates):\n",
        "    # exact match first\n",
        "    if preferred and preferred in df.columns:\n",
        "        return preferred\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    # relaxed: remove non-alnum for matching\n",
        "    def norm(s): return re.sub(r\"[^a-z0-9]\", \"\", str(s).lower())\n",
        "    normmap = {col: norm(col) for col in df.columns}\n",
        "    targets = ([preferred] if preferred else []) + list(candidates)\n",
        "    for t in targets:\n",
        "        key = norm(t)\n",
        "        for col, nm in normmap.items():\n",
        "            if nm == key:\n",
        "                return col\n",
        "    return None\n",
        "\n",
        "INTAKE = pick_col(raw, None, [\"Open Conf Date\",\"Open Conf. Date\",\"Open Conference Date\"])\n",
        "ZIPCOL = pick_col(raw, None, [\"GeoZip\",\"Geo Zip\",\"Site Zip\",\"Site  Zip\"])\n",
        "COUNTY = pick_col(raw, None, [\"GeoCounty\",\"Geo County\",\"Site County\",\"County\"])\n",
        "\n",
        "print(\"Resolved columns →\", \"intake:\", INTAKE, \"| zip:\", ZIPCOL, \"| county:\", COUNTY)\n",
        "\n",
        "if INTAKE is None:\n",
        "    raise ValueError(\"Could not locate an intake date column on 'Complaints' with header=14.\")\n",
        "\n",
        "dt = pd.to_datetime(raw[INTAKE], errors=\"coerce\")\n",
        "mask_years = dt.dt.year.isin(YEARS)\n",
        "cal_y = raw.loc[mask_years].copy()\n",
        "cal_y[\"__intake\"] = dt.loc[mask_years]\n",
        "\n",
        "# ZIP→5 and geo merge\n",
        "cal_y[\"ZIP\"] = cal_y[ZIPCOL].astype(str).apply(zip5) if ZIPCOL else \"\"\n",
        "merged = cal_y[[\"ZIP\"]].rename(columns={\"ZIP\":\"ZIP5\"}).merge(geo, how=\"left\", on=\"ZIP5\")\n",
        "merged.index = cal_y.index\n",
        "\n",
        "# County resolution (B and 1)\n",
        "county_from_agency = (cal_y[COUNTY] if COUNTY else \"\").fillna(\"\").astype(str).str.strip()\n",
        "county_from_zip = merged[\"GeoCounty\"].fillna(\"\").astype(str).str.strip()\n",
        "cal_y[\"County_resolved\"] = np.where(\n",
        "    (cal_y[\"ZIP\"] != \"\") & (county_from_zip != \"\"),\n",
        "    county_from_zip,\n",
        "    county_from_agency\n",
        ")\n",
        "\n",
        "# Rural flag + quick counts\n",
        "cal_y[\"Is_Rural_Worker\"] = cal_y[\"County_resolved\"].apply(lambda c: \"Y\" if c in RURAL_COUNTIES else \"N\")\n",
        "\n",
        "print(\"Cal/OSHA in YEARS:\", len(cal_y))\n",
        "print(\"\\nTop counties:\\n\", cal_y[\"County_resolved\"].value_counts().head(15))\n",
        "print(\"\\nRural flag counts:\\n\", cal_y[\"Is_Rural_Worker\"].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_heXvfGSAuW_",
        "outputId": "58376fdc-ef2d-4fa0-d4cf-bece7164bae5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolved columns → intake: Open Conf Date | zip: GeoZip | county: GeoCounty\n",
            "Cal/OSHA in YEARS: 144\n",
            "\n",
            "Top counties:\n",
            " County_resolved\n",
            "Los Angeles       32\n",
            "Fresno            21\n",
            "San Diego         12\n",
            "Riverside          8\n",
            "Tulare             8\n",
            "Kern               8\n",
            "Sacramento         7\n",
            "Kings              5\n",
            "Imperial           5\n",
            "Contra Costa       5\n",
            "Madera             4\n",
            "Yolo               4\n",
            "San Bernardino     4\n",
            "Ventura            2\n",
            "Stanislaus         2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Rural flag counts:\n",
            " Is_Rural_Worker\n",
            "N    85\n",
            "Y    59\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}